#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æå¼€ç›˜ä»·å’Œå‰ä¸€æ—¥æ”¶ç›˜ä»·æ¯”ç‡çš„è„šæœ¬
ç”¨äºå¤„ç†å¼€ç›˜ä»·ç¼ºå¤±æ—¶çš„å¡«å……ç­–ç•¥
"""

import sys
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.database.connector import JuyuanDB

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('output/logs/open_close_ratio_analysis.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class OpenCloseRatioAnalyzer:
    """å¼€ç›˜ä»·å’Œå‰ä¸€æ—¥æ”¶ç›˜ä»·æ¯”ç‡åˆ†æå™¨"""
    
    def __init__(self, start_date='2024-01-01', end_date='2024-12-31'):
        self.start_date = start_date
        self.end_date = end_date
        self.output_dir = Path('output/processed_data/open_close_analysis')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
    def fetch_data(self):
        """è·å–è‚¡ç¥¨æ•°æ®"""
        logging.info(f"å¼€å§‹è·å–æ•°æ®: {self.start_date} åˆ° {self.end_date}")
        
        try:
            db = JuyuanDB()
            
            # æŸ¥è¯¢è‚¡ç¥¨æ•°æ®ï¼ŒåŒ…å«å‰ä¸€æ—¥æ”¶ç›˜ä»·
            sql = f"""
            SELECT 
                c.SecuCode,
                c.SecuMarket,
                c.ListedSector,
                a.TradingDay,
                a.OpenPrice,
                a.ClosePrice,
                LAG(a.ClosePrice) OVER (PARTITION BY a.InnerCode ORDER BY a.TradingDay) as PrevClosePrice,
                a.Ifsuspend
            FROM QT_DailyQuote a
            LEFT JOIN SecuMain c ON a.InnerCode = c.InnerCode
            WHERE c.SecuCategory = 1 
                AND c.ListedState = 1
                AND c.SecuMarket IN (83, 90)
                AND a.TradingDay BETWEEN '{self.start_date}' AND '{self.end_date}'
                AND a.OpenPrice IS NOT NULL
                AND a.ClosePrice IS NOT NULL
            ORDER BY a.TradingDay, c.SecuCode
            """
            
            df = db.read_sql(sql)
            db.close()
            
            logging.info(f"è·å–æ•°æ®å®Œæˆï¼Œå…± {len(df)} è¡Œ")
            return df
            
        except Exception as e:
            logging.error(f"è·å–æ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def fetch_data_with_sampling(self):
        """è·å–è‚¡ç¥¨æ•°æ®ï¼ˆä½¿ç”¨éšæœºé‡‡æ ·ï¼‰"""
        logging.info(f"å¼€å§‹è·å–æ•°æ®ï¼ˆéšæœºé‡‡æ ·ï¼‰: {self.start_date} åˆ° {self.end_date}")
        
        try:
            db = JuyuanDB()
            
            # ç”Ÿæˆæœˆåº¦æ—¶é—´èŒƒå›´
            monthly_ranges = self.generate_monthly_ranges()
            all_sampled_data = []
            
            for month_range in monthly_ranges:
                year = month_range['year']
                month = month_range['month']
                start = month_range['start']
                end = month_range['end']
                
                logging.info(f"é‡‡æ · {year}å¹´{month}æœˆ æ•°æ® ({start} åˆ° {end})")
                
                # æŸ¥è¯¢å•æœˆæ•°æ®
                sql = f"""
                SELECT 
                    c.SecuCode,
                    c.SecuMarket,
                    c.ListedSector,
                    a.TradingDay,
                    a.OpenPrice,
                    a.ClosePrice,
                    LAG(a.ClosePrice) OVER (PARTITION BY a.InnerCode ORDER BY a.TradingDay) as PrevClosePrice,
                    a.Ifsuspend
                FROM QT_DailyQuote a
                LEFT JOIN SecuMain c ON a.InnerCode = c.InnerCode
                WHERE c.SecuCategory = 1 
                    AND c.ListedState = 1
                    AND c.SecuMarket IN (83, 90)
                    AND a.TradingDay BETWEEN '{start}' AND '{end}'
                    AND a.OpenPrice IS NOT NULL
                    AND a.ClosePrice IS NOT NULL
                ORDER BY a.TradingDay, c.SecuCode
                """
                
                month_df = db.read_sql(sql)
                
                if not month_df.empty:
                    # éšæœºé‡‡æ ·1000æ¡æ•°æ®
                    sample_size = min(1000, len(month_df))
                    if len(month_df) > sample_size:
                        sampled_df = month_df.sample(n=sample_size, random_state=42)
                        logging.info(f"{year}å¹´{month}æœˆ: æ€»æ•°æ®{len(month_df)}è¡Œï¼Œéšæœºé‡‡æ ·{sample_size}è¡Œ")
                    else:
                        sampled_df = month_df
                        logging.info(f"{year}å¹´{month}æœˆ: æ€»æ•°æ®{len(month_df)}è¡Œï¼Œå…¨éƒ¨é‡‡æ ·")
                    
                    # æ·»åŠ é‡‡æ ·æ ‡è¯†
                    sampled_df['SampleYear'] = year
                    sampled_df['SampleMonth'] = month
                    sampled_df['SampleType'] = 'Random'
                    
                    all_sampled_data.append(sampled_df)
                else:
                    logging.warning(f"{year}å¹´{month}æœˆ: æ— æ•°æ®")
            
            db.close()
            
            if all_sampled_data:
                # åˆå¹¶æ‰€æœ‰é‡‡æ ·æ•°æ®
                df = pd.concat(all_sampled_data, ignore_index=True)
                logging.info(f"é‡‡æ ·æ•°æ®è·å–å®Œæˆï¼Œå…± {len(df)} è¡Œ")
                
                # ä¿å­˜é‡‡æ ·æ•°æ®
                sample_file = self.output_dir / 'sampled_data.csv'
                df.to_csv(sample_file, index=False, encoding='utf-8-sig')
                logging.info(f"é‡‡æ ·æ•°æ®å·²ä¿å­˜åˆ°: {sample_file}")
                
                return df
            else:
                logging.error("æ‰€æœ‰æœˆä»½éƒ½æ²¡æœ‰æ•°æ®")
                return pd.DataFrame()
                
        except Exception as e:
            logging.error(f"è·å–é‡‡æ ·æ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def generate_monthly_ranges(self):
        """ç”Ÿæˆæœˆåº¦æ—¶é—´èŒƒå›´"""
        start = datetime.strptime(self.start_date, '%Y-%m-%d')
        end = datetime.strptime(self.end_date, '%Y-%m-%d')
        
        ranges = []
        current = start.replace(day=1)
        
        while current <= end:
            # è®¡ç®—å½“æœˆç»“æŸæ—¥æœŸ
            if current.month == 12:
                next_month = current.replace(year=current.year + 1, month=1)
            else:
                next_month = current.replace(month=current.month + 1)
            
            month_end = next_month - timedelta(days=1)
            
            # ç¡®ä¿ä¸è¶…è¿‡æ€»ä½“ç»“æŸæ—¥æœŸ
            if month_end > end:
                month_end = end
            
            ranges.append({
                'year': current.year,
                'month': current.month,
                'start': current.strftime('%Y-%m-%d'),
                'end': month_end.strftime('%Y-%m-%d')
            })
            
            current = next_month
        
        return ranges
    
    def calculate_ratios(self, df):
        """è®¡ç®—å¼€ç›˜ä»·å’Œå‰ä¸€æ—¥æ”¶ç›˜ä»·çš„æ¯”ç‡"""
        logging.info("å¼€å§‹è®¡ç®—æ¯”ç‡...")
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        valid_df = df[
            (df['OpenPrice'] > 0) & 
            (df['PrevClosePrice'] > 0) & 
            (df['Ifsuspend'] != 1)  # æ’é™¤åœç‰Œæ•°æ®
        ].copy()
        
        # è®¡ç®—æ¯”ç‡
        valid_df['OpenCloseRatio'] = valid_df['OpenPrice'] / valid_df['PrevClosePrice']
        valid_df['OpenCloseRatioPct'] = (valid_df['OpenCloseRatio'] - 1) * 100  # ç™¾åˆ†æ¯”
        
        # è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡
        valid_df['LogReturn'] = np.log(valid_df['OpenCloseRatio'])
        
        logging.info(f"æœ‰æ•ˆæ•°æ®è¡Œæ•°: {len(valid_df)}")
        return valid_df
    
    def analyze_distribution(self, df):
        """åˆ†ææ¯”ç‡åˆ†å¸ƒ"""
        logging.info("åˆ†ææ¯”ç‡åˆ†å¸ƒ...")
        
        # åŸºæœ¬ç»Ÿè®¡
        stats = {
            'æ ·æœ¬æ•°': len(df),
            'å¹³å‡æ¯”ç‡': df['OpenCloseRatio'].mean(),
            'ä¸­ä½æ•°æ¯”ç‡': df['OpenCloseRatio'].median(),
            'æ ‡å‡†å·®': df['OpenCloseRatio'].std(),
            'æœ€å°å€¼': df['OpenCloseRatio'].min(),
            'æœ€å¤§å€¼': df['OpenCloseRatio'].max(),
            '25%åˆ†ä½æ•°': df['OpenCloseRatio'].quantile(0.25),
            '75%åˆ†ä½æ•°': df['OpenCloseRatio'].quantile(0.75),
            '95%åˆ†ä½æ•°': df['OpenCloseRatio'].quantile(0.95),
            '99%åˆ†ä½æ•°': df['OpenCloseRatio'].quantile(0.99),
        }
        
        # ç™¾åˆ†æ¯”ç»Ÿè®¡
        pct_stats = {
            'å¹³å‡æ¶¨è·Œå¹…(%)': df['OpenCloseRatioPct'].mean(),
            'ä¸­ä½æ•°æ¶¨è·Œå¹…(%)': df['OpenCloseRatioPct'].median(),
            'æ¶¨è·Œå¹…æ ‡å‡†å·®(%)': df['OpenCloseRatioPct'].std(),
            'æœ€å¤§æ¶¨å¹…(%)': df['OpenCloseRatioPct'].max(),
            'æœ€å¤§è·Œå¹…(%)': df['OpenCloseRatioPct'].min(),
        }
        
        # åˆå¹¶ç»Ÿè®¡
        all_stats = {**stats, **pct_stats}
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        stats_df = pd.DataFrame(list(all_stats.items()), columns=['æŒ‡æ ‡', 'å€¼'])
        stats_file = self.output_dir / 'open_close_ratio_stats.csv'
        stats_df.to_csv(stats_file, index=False, encoding='utf-8-sig')
        logging.info(f"ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {stats_file}")
        
        return all_stats
    
    def analyze_by_sector(self, df):
        """æŒ‰æ¿å—åˆ†ææ¯”ç‡"""
        logging.info("æŒ‰æ¿å—åˆ†ææ¯”ç‡...")
        
        sector_stats = []
        
        for sector_id in df['ListedSector'].unique():
            if pd.isna(sector_id):
                continue
                
            sector_data = df[df['ListedSector'] == sector_id]
            
            if len(sector_data) == 0:
                continue
            
            sector_name = self.get_sector_name(sector_id)
            
            stats = {
                'æ¿å—ID': sector_id,
                'æ¿å—åç§°': sector_name,
                'æ ·æœ¬æ•°': len(sector_data),
                'å¹³å‡æ¯”ç‡': sector_data['OpenCloseRatio'].mean(),
                'ä¸­ä½æ•°æ¯”ç‡': sector_data['OpenCloseRatio'].median(),
                'æ ‡å‡†å·®': sector_data['OpenCloseRatio'].std(),
                'å¹³å‡æ¶¨è·Œå¹…(%)': sector_data['OpenCloseRatioPct'].mean(),
                'ä¸­ä½æ•°æ¶¨è·Œå¹…(%)': sector_data['OpenCloseRatioPct'].median(),
            }
            
            sector_stats.append(stats)
        
        sector_df = pd.DataFrame(sector_stats)
        sector_file = self.output_dir / 'sector_ratio_stats.csv'
        sector_df.to_csv(sector_file, index=False, encoding='utf-8-sig')
        logging.info(f"æ¿å—ç»Ÿè®¡å·²ä¿å­˜åˆ°: {sector_file}")
        
        return sector_df
    
    def analyze_extreme_cases(self, df):
        """åˆ†ææç«¯æƒ…å†µ"""
        logging.info("åˆ†ææç«¯æƒ…å†µ...")
        
        # æ‰¾å‡ºæç«¯æ¯”ç‡ï¼ˆè¶…è¿‡3ä¸ªæ ‡å‡†å·®ï¼‰
        mean_ratio = df['OpenCloseRatio'].mean()
        std_ratio = df['OpenCloseRatio'].std()
        threshold = 3 * std_ratio
        
        extreme_cases = df[
            (df['OpenCloseRatio'] > mean_ratio + threshold) |
            (df['OpenCloseRatio'] < mean_ratio - threshold)
        ].copy()
        
        extreme_cases = extreme_cases.sort_values('OpenCloseRatio', ascending=False)
        
        # ä¿å­˜æç«¯æƒ…å†µ
        extreme_file = self.output_dir / 'extreme_open_close_ratios.csv'
        extreme_cases.to_csv(extreme_file, index=False, encoding='utf-8-sig')
        logging.info(f"æç«¯æƒ…å†µå·²ä¿å­˜åˆ°: {extreme_file}ï¼Œå…± {len(extreme_cases)} æ¡")
        
        return extreme_cases
    
    def generate_fill_strategies(self, stats):
        """ç”Ÿæˆå¼€ç›˜ä»·ç¼ºå¤±æ—¶çš„å¡«å……ç­–ç•¥"""
        logging.info("ç”Ÿæˆå¡«å……ç­–ç•¥...")
        
        strategies = {
            'ç­–ç•¥1_ç®€å•å‰æ”¶': {
                'æè¿°': 'ç›´æ¥ç”¨å‰ä¸€æ—¥æ”¶ç›˜ä»·å¡«å……',
                'å…¬å¼': 'OpenPrice = PrevClosePrice',
                'é€‚ç”¨åœºæ™¯': 'ä¸€èˆ¬æƒ…å†µï¼Œç®€å•å¿«é€Ÿ',
                'ä¼˜ç‚¹': 'ç®€å•ã€å¿«é€Ÿã€æ— åå·®',
                'ç¼ºç‚¹': 'å¿½ç•¥äº†å¼€ç›˜ä»·é€šå¸¸ä¸æ”¶ç›˜ä»·æœ‰å·®å¼‚çš„äº‹å®'
            },
            'ç­–ç•¥2_å¹³å‡æ¯”ç‡': {
                'æè¿°': 'ä½¿ç”¨å†å²å¹³å‡æ¯”ç‡è°ƒæ•´',
                'å…¬å¼': f'OpenPrice = PrevClosePrice * {stats["å¹³å‡æ¯”ç‡"]:.4f}',
                'é€‚ç”¨åœºæ™¯': 'éœ€è¦åæ˜ å†å²å¹³å‡å¼€ç›˜ä»·ç‰¹å¾',
                'ä¼˜ç‚¹': 'è€ƒè™‘äº†å†å²å¹³å‡å¼€ç›˜ä»·ç‰¹å¾',
                'ç¼ºç‚¹': 'å¯èƒ½ä¸å¤Ÿç²¾ç¡®ï¼Œå¿½ç•¥äº†å¸‚åœºçŠ¶æ€'
            },
            'ç­–ç•¥3_ä¸­ä½æ•°æ¯”ç‡': {
                'æè¿°': 'ä½¿ç”¨å†å²ä¸­ä½æ•°æ¯”ç‡è°ƒæ•´',
                'å…¬å¼': f'OpenPrice = PrevClosePrice * {stats["ä¸­ä½æ•°æ¯”ç‡"]:.4f}',
                'é€‚ç”¨åœºæ™¯': 'éœ€è¦ç¨³å¥çš„å¡«å……ç­–ç•¥',
                'ä¼˜ç‚¹': 'å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿï¼Œæ›´ç¨³å¥',
                'ç¼ºç‚¹': 'å¯èƒ½ä¸å¤Ÿç²¾ç¡®'
            },
            'ç­–ç•¥4_æ¿å—ç‰¹å®šæ¯”ç‡': {
                'æè¿°': 'ä½¿ç”¨æ¿å—ç‰¹å®šçš„å¹³å‡æ¯”ç‡',
                'å…¬å¼': 'OpenPrice = PrevClosePrice * SectorAvgRatio',
                'é€‚ç”¨åœºæ™¯': 'ä¸åŒæ¿å—å¼€ç›˜ä»·ç‰¹å¾å·®å¼‚è¾ƒå¤§æ—¶',
                'ä¼˜ç‚¹': 'è€ƒè™‘äº†æ¿å—ç‰¹å¾',
                'ç¼ºç‚¹': 'éœ€è¦æ¿å—æ•°æ®ï¼Œè®¡ç®—å¤æ‚'
            },
            'ç­–ç•¥5_éšæœºæ³¢åŠ¨': {
                'æè¿°': 'åœ¨å¹³å‡æ¯”ç‡åŸºç¡€ä¸Šæ·»åŠ éšæœºæ³¢åŠ¨',
                'å…¬å¼': f'OpenPrice = PrevClosePrice * ({stats["å¹³å‡æ¯”ç‡"]:.4f} + random_noise)',
                'é€‚ç”¨åœºæ™¯': 'éœ€è¦æ¨¡æ‹ŸçœŸå®å¼€ç›˜ä»·çš„éšæœºæ€§',
                'ä¼˜ç‚¹': 'æ›´æ¥è¿‘çœŸå®å¼€ç›˜ä»·çš„éšæœºç‰¹å¾',
                'ç¼ºç‚¹': 'å¼•å…¥äº†éšæœºæ€§ï¼Œç»“æœä¸ç¨³å®š'
            },
            'ç­–ç•¥6_æ¶¨è·Œåœé™åˆ¶': {
                'æè¿°': 'è€ƒè™‘æ¶¨è·Œåœé™åˆ¶çš„å¡«å……',
                'å…¬å¼': 'OpenPrice = min(max(PrevClosePrice * ratio, PriceFloor), PriceCeiling)',
                'é€‚ç”¨åœºæ™¯': 'æœ‰æ¶¨è·Œåœé™åˆ¶çš„å¸‚åœº',
                'ä¼˜ç‚¹': 'ç¬¦åˆå¸‚åœºè§„åˆ™',
                'ç¼ºç‚¹': 'éœ€è¦æ¶¨è·Œåœæ•°æ®'
            }
        }
        
        # ä¿å­˜ç­–ç•¥
        strategies_file = self.output_dir / 'fill_strategies.md'
        with open(strategies_file, 'w', encoding='utf-8') as f:
            f.write("# å¼€ç›˜ä»·ç¼ºå¤±å¡«å……ç­–ç•¥\n\n")
            f.write(f"åŸºäº {self.start_date} åˆ° {self.end_date} çš„æ•°æ®åˆ†æ\n\n")
            f.write("## å…³é”®ç»Ÿè®¡æŒ‡æ ‡\n\n")
            f.write(f"- å¹³å‡å¼€ç›˜ä»·/å‰æ”¶ä»·æ¯”ç‡: {stats['å¹³å‡æ¯”ç‡']:.4f}\n")
            f.write(f"- ä¸­ä½æ•°æ¯”ç‡: {stats['ä¸­ä½æ•°æ¯”ç‡']:.4f}\n")
            f.write(f"- æ ‡å‡†å·®: {stats['æ ‡å‡†å·®']:.4f}\n")
            f.write(f"- å¹³å‡æ¶¨è·Œå¹…: {stats['å¹³å‡æ¶¨è·Œå¹…(%)']:.2f}%\n\n")
            
            f.write("## æ¨èç­–ç•¥\n\n")
            f.write("### 1. å¿«é€Ÿå¡«å……ï¼ˆæ¨èç”¨äºå¤§é‡æ•°æ®ï¼‰\n")
            f.write(f"- ä½¿ç”¨å‰ä¸€æ—¥æ”¶ç›˜ä»· * {stats['å¹³å‡æ¯”ç‡']:.4f}\n")
            f.write(f"- ç®€å•æœ‰æ•ˆï¼Œåå·®è¾ƒå°\n\n")
            
            f.write("### 2. ç²¾ç¡®å¡«å……ï¼ˆæ¨èç”¨äºé‡è¦æ•°æ®ï¼‰\n")
            f.write("- ä½¿ç”¨æ¿å—ç‰¹å®šçš„å¹³å‡æ¯”ç‡\n")
            f.write("- è€ƒè™‘æ¶¨è·Œåœé™åˆ¶\n")
            f.write("- æ·»åŠ é€‚å½“çš„éšæœºæ³¢åŠ¨\n\n")
            
            f.write("## è¯¦ç»†ç­–ç•¥è¯´æ˜\n\n")
            
            for strategy_name, strategy in strategies.items():
                f.write(f"### {strategy_name}\n")
                f.write(f"- **æè¿°**: {strategy['æè¿°']}\n")
                f.write(f"- **å…¬å¼**: {strategy['å…¬å¼']}\n")
                f.write(f"- **é€‚ç”¨åœºæ™¯**: {strategy['é€‚ç”¨åœºæ™¯']}\n")
                f.write(f"- **ä¼˜ç‚¹**: {strategy['ä¼˜ç‚¹']}\n")
                f.write(f"- **ç¼ºç‚¹**: {strategy['ç¼ºç‚¹']}\n\n")
        
        logging.info(f"å¡«å……ç­–ç•¥å·²ä¿å­˜åˆ°: {strategies_file}")
        return strategies
    
    def create_visualizations(self, df):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        logging.info("åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")
        
        # è®¾ç½®å›¾è¡¨æ ·å¼
        plt.style.use('default')
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('å¼€ç›˜ä»·ä¸å‰ä¸€æ—¥æ”¶ç›˜ä»·æ¯”ç‡åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. æ¯”ç‡åˆ†å¸ƒç›´æ–¹å›¾
        axes[0, 0].hist(df['OpenCloseRatio'], bins=100, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 0].axvline(df['OpenCloseRatio'].mean(), color='red', linestyle='--', label=f'å‡å€¼: {df["OpenCloseRatio"].mean():.4f}')
        axes[0, 0].axvline(df['OpenCloseRatio'].median(), color='orange', linestyle='--', label=f'ä¸­ä½æ•°: {df["OpenCloseRatio"].median():.4f}')
        axes[0, 0].set_xlabel('å¼€ç›˜ä»·/å‰æ”¶ä»·æ¯”ç‡')
        axes[0, 0].set_ylabel('é¢‘æ¬¡')
        axes[0, 0].set_title('æ¯”ç‡åˆ†å¸ƒç›´æ–¹å›¾')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. æ¶¨è·Œå¹…åˆ†å¸ƒ
        axes[0, 1].hist(df['OpenCloseRatioPct'], bins=100, alpha=0.7, color='lightgreen', edgecolor='black')
        axes[0, 1].axvline(df['OpenCloseRatioPct'].mean(), color='red', linestyle='--', label=f'å‡å€¼: {df["OpenCloseRatioPct"].mean():.2f}%')
        axes[0, 1].axvline(df['OpenCloseRatioPct'].median(), color='orange', linestyle='--', label=f'ä¸­ä½æ•°: {df["OpenCloseRatioPct"].median():.2f}%')
        axes[0, 1].set_xlabel('å¼€ç›˜æ¶¨è·Œå¹… (%)')
        axes[0, 1].set_ylabel('é¢‘æ¬¡')
        axes[0, 1].set_title('å¼€ç›˜æ¶¨è·Œå¹…åˆ†å¸ƒ')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. å¯¹æ•°æ”¶ç›Šç‡åˆ†å¸ƒ
        axes[1, 0].hist(df['LogReturn'], bins=100, alpha=0.7, color='lightcoral', edgecolor='black')
        axes[1, 0].axvline(df['LogReturn'].mean(), color='red', linestyle='--', label=f'å‡å€¼: {df["LogReturn"].mean():.4f}')
        axes[1, 0].set_xlabel('å¯¹æ•°æ”¶ç›Šç‡')
        axes[1, 0].set_ylabel('é¢‘æ¬¡')
        axes[1, 0].set_title('å¯¹æ•°æ”¶ç›Šç‡åˆ†å¸ƒ')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. æŒ‰æ¿å—çš„ç®±çº¿å›¾
        sector_data = []
        sector_labels = []
        
        for sector_id in sorted(df['ListedSector'].unique()):
            if pd.isna(sector_id):
                continue
            sector_name = self.get_sector_name(sector_id)
            sector_ratios = df[df['ListedSector'] == sector_id]['OpenCloseRatio']
            if len(sector_ratios) > 0:
                sector_data.append(sector_ratios.values)
                sector_labels.append(f'{sector_id}({sector_name})')
        
        if sector_data:
            axes[1, 1].boxplot(sector_data, labels=sector_labels)
            axes[1, 1].set_ylabel('å¼€ç›˜ä»·/å‰æ”¶ä»·æ¯”ç‡')
            axes[1, 1].set_title('å„æ¿å—æ¯”ç‡åˆ†å¸ƒ')
            axes[1, 1].tick_params(axis='x', rotation=45)
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        chart_file = self.output_dir / 'open_close_ratio_analysis.png'
        plt.savefig(chart_file, dpi=300, bbox_inches='tight')
        logging.info(f"å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {chart_file}")
        
        plt.show()
    
    def get_sector_name(self, sector_id):
        """è·å–æ¿å—åç§°"""
        sector_names = {
            1: 'ä¸»æ¿',
            6: 'åˆ›ä¸šæ¿',
            7: 'ç§‘åˆ›æ¿'
        }
        return sector_names.get(sector_id, f'æœªçŸ¥æ¿å—({sector_id})')
    
    def run_analysis(self, use_sampling=True):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        logging.info("å¼€å§‹å¼€ç›˜ä»·ä¸å‰ä¸€æ—¥æ”¶ç›˜ä»·æ¯”ç‡åˆ†æ")
        
        # 1. è·å–æ•°æ®
        if use_sampling:
            logging.info("ä½¿ç”¨éšæœºé‡‡æ ·æ¨¡å¼")
            df = self.fetch_data_with_sampling()
        else:
            logging.info("ä½¿ç”¨å…¨é‡æ•°æ®æ¨¡å¼")
            df = self.fetch_data()
            
        if df.empty:
            logging.error("æ— æ³•è·å–æ•°æ®ï¼Œåˆ†æç»ˆæ­¢")
            return
        
        # 2. è®¡ç®—æ¯”ç‡
        df_with_ratios = self.calculate_ratios(df)
        if df_with_ratios.empty:
            logging.error("æ— æ³•è®¡ç®—æ¯”ç‡ï¼Œåˆ†æç»ˆæ­¢")
            return
        
        # 3. åˆ†æåˆ†å¸ƒ
        stats = self.analyze_distribution(df_with_ratios)
        
        # 4. æŒ‰æ¿å—åˆ†æ
        sector_stats = self.analyze_by_sector(df_with_ratios)
        
        # 5. åˆ†ææç«¯æƒ…å†µ
        extreme_cases = self.analyze_extreme_cases(df_with_ratios)
        
        # 6. åˆ†ææ³¢åŠ¨ç‡å’Œå™ªå£°å¡«å……èŒƒå›´
        volatility_stats, error_distribution = self.analyze_volatility_and_noise(df_with_ratios)
        
        # 7. ç”Ÿæˆå¡«å……ç­–ç•¥
        strategies = self.generate_fill_strategies(stats)
        
        # 8. ç”Ÿæˆå™ªå£°å¡«å……ç­–ç•¥
        noise_strategies = self.generate_noise_fill_strategies(volatility_stats, error_distribution)
        
        # 9. åˆ›å»ºå¯è§†åŒ–
        self.create_visualizations(df_with_ratios)
        
        # 10. åˆ›å»ºæ³¢åŠ¨ç‡å¯è§†åŒ–
        self.create_volatility_visualizations(df_with_ratios, error_distribution)
        
        # 11. åˆ†æé‡‡æ ·ç»Ÿè®¡
        sampling_stats, overall_sampling_stats = self.analyze_sampling_statistics(df)
        
        # 12. è¾“å‡ºæ€»ç»“
        self.print_summary(stats, sector_stats, extreme_cases, volatility_stats, error_distribution, sampling_stats, overall_sampling_stats)
        
        logging.info("åˆ†æå®Œæˆ")
    
    def print_summary(self, stats, sector_stats, extreme_cases, volatility_stats, error_distribution, sampling_stats, overall_sampling_stats):
        """æ‰“å°åˆ†ææ€»ç»“"""
        print("\n" + "="*60)
        print("å¼€ç›˜ä»·ä¸å‰ä¸€æ—¥æ”¶ç›˜ä»·æ¯”ç‡åˆ†ææ€»ç»“")
        print("="*60)
        
        print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"  æ ·æœ¬æ•°: {stats['æ ·æœ¬æ•°']:,}")
        print(f"  å¹³å‡æ¯”ç‡: {stats['å¹³å‡æ¯”ç‡']:.4f}")
        print(f"  ä¸­ä½æ•°æ¯”ç‡: {stats['ä¸­ä½æ•°æ¯”ç‡']:.4f}")
        print(f"  æ ‡å‡†å·®: {stats['æ ‡å‡†å·®']:.4f}")
        print(f"  å¹³å‡æ¶¨è·Œå¹…: {stats['å¹³å‡æ¶¨è·Œå¹…(%)']:.2f}%")
        
        print(f"\nğŸ“ˆ åˆ†ä½æ•°ç»Ÿè®¡:")
        print(f"  25%åˆ†ä½æ•°: {stats['25%åˆ†ä½æ•°']:.4f}")
        print(f"  75%åˆ†ä½æ•°: {stats['75%åˆ†ä½æ•°']:.4f}")
        print(f"  95%åˆ†ä½æ•°: {stats['95%åˆ†ä½æ•°']:.4f}")
        print(f"  99%åˆ†ä½æ•°: {stats['99%åˆ†ä½æ•°']:.4f}")
        
        print(f"\nğŸ¢ æ¿å—åˆ†æ:")
        for _, row in sector_stats.iterrows():
            print(f"  {row['æ¿å—åç§°']}: å¹³å‡æ¯”ç‡={row['å¹³å‡æ¯”ç‡']:.4f}, æ ·æœ¬æ•°={row['æ ·æœ¬æ•°']:,}")
        
        print(f"\nâš ï¸  æç«¯æƒ…å†µ:")
        print(f"  æç«¯æ¯”ç‡æ•°é‡: {len(extreme_cases):,}")
        print(f"  æç«¯æ¯”ç‡å æ¯”: {len(extreme_cases)/stats['æ ·æœ¬æ•°']*100:.2f}%")
        
        print(f"\nğŸ“Š æ³¢åŠ¨ç‡åˆ†æ:")
        print(f"  æ³¢åŠ¨ç‡(æ ‡å‡†å·®): {volatility_stats['æ³¢åŠ¨ç‡(æ ‡å‡†å·®)']:.6f}")
        print(f"  æ³¢åŠ¨ç‡ç™¾åˆ†æ¯”: {volatility_stats['æ³¢åŠ¨ç‡(%)']:.4f}%")
        print(f"  Â±0.1%å™ªå£°è¦†ç›–ç‡: {volatility_stats['Â±0.1%è¦†ç›–ç‡(%)']:.2f}%")
        print(f"  Â±1.2%è¯¯å·®è¦†ç›–ç‡: {volatility_stats['Â±1.2%è¦†ç›–ç‡(%)']:.2f}%")
        
        print(f"\nğŸ“ˆ è¯¯å·®åˆ†å¸ƒ:")
        for error_info in error_distribution:
            print(f"  {error_info['è¯¯å·®èŒƒå›´']}: {error_info['æ•°æ®é‡']:,} æ¡ ({error_info['è¦†ç›–ç‡(%)']:.2f}%)")
        
        print(f"\nğŸ“Š é‡‡æ ·ç»Ÿè®¡:")
        for _, row in sampling_stats.iterrows():
            print(f"  é‡‡æ ·æœˆä»½: {row['å¹´æœˆ']}")
            print(f"  æ ·æœ¬æ•°: {row['æ ·æœ¬æ•°']:,}")
            print(f"  å¹³å‡æ¯”ç‡: {row['å¹³å‡æ¯”ç‡']:.4f}")
            print(f"  æ¯”ç‡æ ‡å‡†å·®: {row['æ¯”ç‡æ ‡å‡†å·®']:.4f}")
            print(f"  æœ€å°æ¯”ç‡: {row['æœ€å°æ¯”ç‡']:.4f}")
            print(f"  æœ€å¤§æ¯”ç‡: {row['æœ€å¤§æ¯”ç‡']:.4f}")
            print(f"  å¹³å‡æ¶¨è·Œå¹…: {row['å¹³å‡æ¶¨è·Œå¹…']:.2f}%")
            print(f"  æ¶¨è·Œå¹…æ ‡å‡†å·®: {row['æ¶¨è·Œå¹…æ ‡å‡†å·®']:.2f}%")
            print(f"  æœ€å°æ¶¨è·Œå¹…: {row['æœ€å°æ¶¨è·Œå¹…']:.2f}%")
            print(f"  æœ€å¤§æ¶¨è·Œå¹…: {row['æœ€å¤§æ¶¨è·Œå¹…']:.2f}%")
        
        print(f"\nğŸ“Š æ€»ä½“é‡‡æ ·ç»Ÿè®¡:")
        for key, value in overall_sampling_stats.items():
            print(f"  {key}: {value}")
        
        print(f"\nğŸ’¡ æ¨èå¡«å……ç­–ç•¥:")
        print(f"  1. å¿«é€Ÿå¡«å……: å‰æ”¶ä»· * {stats['å¹³å‡æ¯”ç‡']:.4f}")
        print(f"  2. ç¨³å¥å¡«å……: å‰æ”¶ä»· * {stats['ä¸­ä½æ•°æ¯”ç‡']:.4f}")
        print(f"  3. ç²¾ç¡®å¡«å……: ä½¿ç”¨æ¿å—ç‰¹å®šæ¯”ç‡")
        
        print(f"\nğŸ¯ å™ªå£°å¡«å……ç­–ç•¥:")
        print(f"  1. ä¿å®ˆå™ªå£°(Â±0.1%): è¦†ç›–ç‡ {volatility_stats['Â±0.1%è¦†ç›–ç‡(%)']:.2f}%")
        print(f"  2. æ ‡å‡†å™ªå£°(Â±{volatility_stats['æ³¢åŠ¨ç‡(%)']:.4f}%): è¦†ç›–ç‡çº¦68%")
        print(f"  3. å®‰å…¨å™ªå£°(Â±1.2%): è¦†ç›–ç‡ {volatility_stats['Â±1.2%è¦†ç›–ç‡(%)']:.2f}%")
        
        print(f"\nğŸ“ ç»“æœæ–‡ä»¶:")
        print(f"  ç»Ÿè®¡ç»“æœ: {self.output_dir / 'open_close_ratio_stats.csv'}")
        print(f"  æ¿å—ç»Ÿè®¡: {self.output_dir / 'sector_ratio_stats.csv'}")
        print(f"  æç«¯æƒ…å†µ: {self.output_dir / 'extreme_open_close_ratios.csv'}")
        print(f"  æ³¢åŠ¨ç‡åˆ†æ: {self.output_dir / 'volatility_analysis.csv'}")
        print(f"  è¯¯å·®åˆ†å¸ƒ: {self.output_dir / 'error_distribution.csv'}")
        print(f"  å¡«å……ç­–ç•¥: {self.output_dir / 'fill_strategies.md'}")
        print(f"  å™ªå£°ç­–ç•¥: {self.output_dir / 'noise_fill_strategies.md'}")
        print(f"  å¯è§†åŒ–å›¾: {self.output_dir / 'open_close_ratio_analysis.png'}")
        print(f"  æ³¢åŠ¨ç‡å›¾: {self.output_dir / 'volatility_analysis.png'}")
        print(f"  é‡‡æ ·ç»Ÿè®¡: {self.output_dir / 'sampling_statistics.csv'}")
        print(f"  æ€»ä½“é‡‡æ ·ç»Ÿè®¡: {self.output_dir / 'overall_sampling_stats.csv'}")
        
        print("="*60)
    
    def analyze_volatility_and_noise(self, df):
        """åˆ†ææ³¢åŠ¨ç‡å’Œå™ªå£°å¡«å……èŒƒå›´"""
        logging.info("åˆ†ææ³¢åŠ¨ç‡å’Œå™ªå£°å¡«å……èŒƒå›´...")
        
        # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆæ ‡å‡†å·®ï¼‰
        volatility = df['OpenCloseRatio'].std()
        volatility_pct = volatility * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        
        # è®¡ç®—Â±0.1%å™ªå£°èŒƒå›´
        noise_range = 0.001  # Â±0.1%
        noise_lower = 1.0 - noise_range
        noise_upper = 1.0 + noise_range
        
        # è®¡ç®—åœ¨å™ªå£°èŒƒå›´å†…çš„æ•°æ®æ¯”ä¾‹
        within_noise_range = df[
            (df['OpenCloseRatio'] >= noise_lower) & 
            (df['OpenCloseRatio'] <= noise_upper)
        ]
        noise_coverage = len(within_noise_range) / len(df) * 100
        
        # è®¡ç®—æ³¢åŠ¨ç‡è¯¯å·®åˆ†æ
        volatility_error_threshold = 0.012  # 1.2%
        within_volatility_error = df[
            (df['OpenCloseRatio'] >= 1.0 - volatility_error_threshold) & 
            (df['OpenCloseRatio'] <= 1.0 + volatility_error_threshold)
        ]
        volatility_error_coverage = len(within_volatility_error) / len(df) * 100
        
        # è®¡ç®—ä¸åŒè¯¯å·®èŒƒå›´çš„æ•°æ®åˆ†å¸ƒ
        error_ranges = [
            (0.001, 'Â±0.1%'),
            (0.002, 'Â±0.2%'),
            (0.005, 'Â±0.5%'),
            (0.01, 'Â±1.0%'),
            (0.012, 'Â±1.2%'),
            (0.02, 'Â±2.0%'),
            (0.05, 'Â±5.0%')
        ]
        
        error_distribution = []
        for error_range, label in error_ranges:
            within_range = df[
                (df['OpenCloseRatio'] >= 1.0 - error_range) & 
                (df['OpenCloseRatio'] <= 1.0 + error_range)
            ]
            coverage = len(within_range) / len(df) * 100
            error_distribution.append({
                'è¯¯å·®èŒƒå›´': label,
                'æ•°å€¼èŒƒå›´': error_range,
                'æ•°æ®é‡': len(within_range),
                'è¦†ç›–ç‡(%)': coverage
            })
        
        # ç”Ÿæˆæ³¢åŠ¨ç‡åˆ†ææŠ¥å‘Š
        volatility_stats = {
            'æ³¢åŠ¨ç‡(æ ‡å‡†å·®)': volatility,
            'æ³¢åŠ¨ç‡(%)': volatility_pct,
            'Â±0.1%å™ªå£°èŒƒå›´': f'{noise_lower:.4f} - {noise_upper:.4f}',
            'Â±0.1%è¦†ç›–ç‡(%)': noise_coverage,
            'Â±1.2%è¦†ç›–ç‡(%)': volatility_error_coverage,
            'æ ·æœ¬æ€»æ•°': len(df)
        }
        
        # ä¿å­˜æ³¢åŠ¨ç‡åˆ†æç»“æœ
        volatility_df = pd.DataFrame(list(volatility_stats.items()), columns=['æŒ‡æ ‡', 'å€¼'])
        volatility_file = self.output_dir / 'volatility_analysis.csv'
        volatility_df.to_csv(volatility_file, index=False, encoding='utf-8-sig')
        
        # ä¿å­˜è¯¯å·®åˆ†å¸ƒ
        error_df = pd.DataFrame(error_distribution)
        error_file = self.output_dir / 'error_distribution.csv'
        error_df.to_csv(error_file, index=False, encoding='utf-8-sig')
        
        logging.info(f"æ³¢åŠ¨ç‡åˆ†æå·²ä¿å­˜åˆ°: {volatility_file}")
        logging.info(f"è¯¯å·®åˆ†å¸ƒå·²ä¿å­˜åˆ°: {error_file}")
        
        return volatility_stats, error_distribution
    
    def generate_noise_fill_strategies(self, volatility_stats, error_distribution):
        """ç”ŸæˆåŸºäºæ³¢åŠ¨ç‡çš„å™ªå£°å¡«å……ç­–ç•¥"""
        logging.info("ç”Ÿæˆå™ªå£°å¡«å……ç­–ç•¥...")
        
        # è·å–å…³é”®æŒ‡æ ‡
        volatility = volatility_stats['æ³¢åŠ¨ç‡(æ ‡å‡†å·®)']
        noise_coverage = volatility_stats['Â±0.1%è¦†ç›–ç‡(%)']
        error_1_2_coverage = volatility_stats['Â±1.2%è¦†ç›–ç‡(%)']
        
        # ç”Ÿæˆç­–ç•¥
        noise_strategies = {
            'ç­–ç•¥1_ä¿å®ˆå™ªå£°': {
                'æè¿°': 'ä½¿ç”¨Â±0.1%çš„ä¿å®ˆå™ªå£°èŒƒå›´',
                'å…¬å¼': f'OpenPrice = PrevClosePrice * (1.0 + random(-0.001, 0.001))',
                'è¦†ç›–ç‡': f'{noise_coverage:.2f}%',
                'é€‚ç”¨åœºæ™¯': 'éœ€è¦æœ€å°åå·®çš„ç²¾ç¡®å¡«å……',
                'ä¼˜ç‚¹': 'åå·®æå°ï¼Œç¬¦åˆå¤§éƒ¨åˆ†çœŸå®æƒ…å†µ',
                'ç¼ºç‚¹': 'å¯èƒ½ä¸å¤Ÿéšæœºï¼Œç¼ºä¹çœŸå®æ³¢åŠ¨'
            },
            'ç­–ç•¥2_æ ‡å‡†å™ªå£°': {
                'æè¿°': 'ä½¿ç”¨1å€æ ‡å‡†å·®çš„å™ªå£°èŒƒå›´',
                'å…¬å¼': f'OpenPrice = PrevClosePrice * (1.0 + random(-{volatility:.4f}, {volatility:.4f}))',
                'è¦†ç›–ç‡': 'çº¦68%',
                'é€‚ç”¨åœºæ™¯': 'å¹³è¡¡ç²¾åº¦å’ŒçœŸå®æ€§çš„æ ‡å‡†å¡«å……',
                'ä¼˜ç‚¹': 'ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼ŒçœŸå®æ€§å¼º',
                'ç¼ºç‚¹': 'åå·®ç›¸å¯¹è¾ƒå¤§'
            },
            'ç­–ç•¥3_å®‰å…¨å™ªå£°': {
                'æè¿°': 'ä½¿ç”¨Â±1.2%çš„å®‰å…¨å™ªå£°èŒƒå›´',
                'å…¬å¼': 'OpenPrice = PrevClosePrice * (1.0 + random(-0.012, 0.012))',
                'è¦†ç›–ç‡': f'{error_1_2_coverage:.2f}%',
                'é€‚ç”¨åœºæ™¯': 'éœ€è¦è¦†ç›–å¤§éƒ¨åˆ†çœŸå®æƒ…å†µçš„å¡«å……',
                'ä¼˜ç‚¹': 'è¦†ç›–ç‡é«˜ï¼Œå®‰å…¨æ€§å¥½',
                'ç¼ºç‚¹': 'åå·®è¾ƒå¤§ï¼Œå¯èƒ½ä¸å¤Ÿç²¾ç¡®'
            },
            'ç­–ç•¥4_è‡ªé€‚åº”å™ªå£°': {
                'æè¿°': 'æ ¹æ®æ¿å—ç‰¹å¾è°ƒæ•´å™ªå£°èŒƒå›´',
                'å…¬å¼': 'OpenPrice = PrevClosePrice * (1.0 + random(-sector_vol, sector_vol))',
                'è¦†ç›–ç‡': 'æ¿å—ç‰¹å®š',
                'é€‚ç”¨åœºæ™¯': 'ä¸åŒæ¿å—æ³¢åŠ¨ç‰¹å¾å·®å¼‚è¾ƒå¤§æ—¶',
                'ä¼˜ç‚¹': 'è€ƒè™‘æ¿å—ç‰¹å¾ï¼Œæ›´ç²¾ç¡®',
                'ç¼ºç‚¹': 'éœ€è¦æ¿å—æ•°æ®ï¼Œè®¡ç®—å¤æ‚'
            },
            'ç­–ç•¥5_æ··åˆç­–ç•¥': {
                'æè¿°': 'ç»“åˆå¹³å‡æ¯”ç‡å’Œå™ªå£°',
                'å…¬å¼': f'OpenPrice = PrevClosePrice * ({self.get_average_ratio():.4f} + random(-{volatility:.4f}, {volatility:.4f}))',
                'è¦†ç›–ç‡': 'åŠ¨æ€è°ƒæ•´',
                'é€‚ç”¨åœºæ™¯': 'éœ€è¦åŒæ—¶è€ƒè™‘è¶‹åŠ¿å’Œæ³¢åŠ¨çš„å¡«å……',
                'ä¼˜ç‚¹': 'æ—¢è€ƒè™‘å†å²è¶‹åŠ¿ï¼Œåˆä¿æŒéšæœºæ€§',
                'ç¼ºç‚¹': 'è®¡ç®—å¤æ‚ï¼Œéœ€è¦å†å²æ•°æ®'
            }
        }
        
        # ä¿å­˜å™ªå£°å¡«å……ç­–ç•¥
        noise_file = self.output_dir / 'noise_fill_strategies.md'
        with open(noise_file, 'w', encoding='utf-8') as f:
            f.write("# åŸºäºæ³¢åŠ¨ç‡çš„å™ªå£°å¡«å……ç­–ç•¥\n\n")
            f.write(f"åŸºäº {self.start_date} åˆ° {self.end_date} çš„æ•°æ®åˆ†æ\n\n")
            
            f.write("## å…³é”®æ³¢åŠ¨ç‡æŒ‡æ ‡\n\n")
            f.write(f"- å¼€ç›˜ä»·/å‰æ”¶ä»·æ¯”ç‡æ ‡å‡†å·®: {volatility:.6f}\n")
            f.write(f"- æ³¢åŠ¨ç‡ç™¾åˆ†æ¯”: {volatility*100:.4f}%\n")
            f.write(f"- Â±0.1%å™ªå£°è¦†ç›–ç‡: {noise_coverage:.2f}%\n")
            f.write(f"- Â±1.2%è¯¯å·®è¦†ç›–ç‡: {error_1_2_coverage:.2f}%\n\n")
            
            f.write("## è¯¯å·®åˆ†å¸ƒç»Ÿè®¡\n\n")
            f.write("| è¯¯å·®èŒƒå›´ | æ•°æ®é‡ | è¦†ç›–ç‡ |\n")
            f.write("|---------|--------|--------|\n")
            for error_info in error_distribution:
                f.write(f"| {error_info['è¯¯å·®èŒƒå›´']} | {error_info['æ•°æ®é‡']:,} | {error_info['è¦†ç›–ç‡(%)']:.2f}% |\n")
            f.write("\n")
            
            f.write("## æ¨èç­–ç•¥\n\n")
            f.write("### 1. ç²¾ç¡®å¡«å……ï¼ˆæ¨èç”¨äºå…³é”®æ•°æ®ï¼‰\n")
            f.write(f"- ä½¿ç”¨Â±0.1%å™ªå£°èŒƒå›´\n")
            f.write(f"- è¦†ç›–ç‡: {noise_coverage:.2f}%\n")
            f.write(f"- åå·®æå°ï¼Œé€‚åˆç²¾ç¡®è®¡ç®—\n\n")
            
            f.write("### 2. æ ‡å‡†å¡«å……ï¼ˆæ¨èç”¨äºä¸€èˆ¬æ•°æ®ï¼‰\n")
            f.write(f"- ä½¿ç”¨1å€æ ‡å‡†å·®å™ªå£°èŒƒå›´: Â±{volatility*100:.4f}%\n")
            f.write(f"- ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼ŒçœŸå®æ€§å¼º\n\n")
            
            f.write("### 3. å®‰å…¨å¡«å……ï¼ˆæ¨èç”¨äºé£é™©æ§åˆ¶ï¼‰\n")
            f.write(f"- ä½¿ç”¨Â±1.2%å™ªå£°èŒƒå›´\n")
            f.write(f"- è¦†ç›–ç‡: {error_1_2_coverage:.2f}%\n")
            f.write(f"- è¦†ç›–å¤§éƒ¨åˆ†çœŸå®æƒ…å†µ\n\n")
            
            f.write("## è¯¦ç»†ç­–ç•¥è¯´æ˜\n\n")
            
            for strategy_name, strategy in noise_strategies.items():
                f.write(f"### {strategy_name}\n")
                f.write(f"- **æè¿°**: {strategy['æè¿°']}\n")
                f.write(f"- **å…¬å¼**: {strategy['å…¬å¼']}\n")
                f.write(f"- **è¦†ç›–ç‡**: {strategy['è¦†ç›–ç‡']}\n")
                f.write(f"- **é€‚ç”¨åœºæ™¯**: {strategy['é€‚ç”¨åœºæ™¯']}\n")
                f.write(f"- **ä¼˜ç‚¹**: {strategy['ä¼˜ç‚¹']}\n")
                f.write(f"- **ç¼ºç‚¹**: {strategy['ç¼ºç‚¹']}\n\n")
        
        logging.info(f"å™ªå£°å¡«å……ç­–ç•¥å·²ä¿å­˜åˆ°: {noise_file}")
        return noise_strategies
    
    def get_average_ratio(self):
        """è·å–å¹³å‡æ¯”ç‡ï¼ˆç”¨äºæ··åˆç­–ç•¥ï¼‰"""
        # è¿™é‡Œå¯ä»¥ä»ä¹‹å‰çš„åˆ†æç»“æœä¸­è·å–ï¼Œæš‚æ—¶è¿”å›1.0
        return 1.0
    
    def create_volatility_visualizations(self, df, error_distribution):
        """åˆ›å»ºæ³¢åŠ¨ç‡ç›¸å…³çš„å¯è§†åŒ–å›¾è¡¨"""
        logging.info("åˆ›å»ºæ³¢åŠ¨ç‡å¯è§†åŒ–å›¾è¡¨...")
        
        # åˆ›å»ºæ–°çš„å›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('å¼€ç›˜ä»·æ³¢åŠ¨ç‡åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. æ³¢åŠ¨ç‡åˆ†å¸ƒï¼ˆå¯¹æ•°æ”¶ç›Šç‡ï¼‰
        axes[0, 0].hist(df['LogReturn'], bins=100, alpha=0.7, color='lightblue', edgecolor='black')
        axes[0, 0].axvline(df['LogReturn'].mean(), color='red', linestyle='--', label=f'å‡å€¼: {df["LogReturn"].mean():.6f}')
        axes[0, 0].axvline(df['LogReturn'].mean() + df['LogReturn'].std(), color='orange', linestyle='--', label=f'+1Ïƒ: {df["LogReturn"].mean() + df["LogReturn"].std():.6f}')
        axes[0, 0].axvline(df['LogReturn'].mean() - df['LogReturn'].std(), color='orange', linestyle='--', label=f'-1Ïƒ: {df["LogReturn"].mean() - df["LogReturn"].std():.6f}')
        axes[0, 0].set_xlabel('å¯¹æ•°æ”¶ç›Šç‡')
        axes[0, 0].set_ylabel('é¢‘æ¬¡')
        axes[0, 0].set_title('å¯¹æ•°æ”¶ç›Šç‡åˆ†å¸ƒï¼ˆæ³¢åŠ¨ç‡åˆ†æï¼‰')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. è¯¯å·®èŒƒå›´è¦†ç›–ç‡
        error_ranges = [info['è¯¯å·®èŒƒå›´'] for info in error_distribution]
        coverages = [info['è¦†ç›–ç‡(%)'] for info in error_distribution]
        
        axes[0, 1].bar(error_ranges, coverages, color='lightgreen', alpha=0.7)
        axes[0, 1].set_xlabel('è¯¯å·®èŒƒå›´')
        axes[0, 1].set_ylabel('è¦†ç›–ç‡ (%)')
        axes[0, 1].set_title('ä¸åŒè¯¯å·®èŒƒå›´çš„æ•°æ®è¦†ç›–ç‡')
        axes[0, 1].tick_params(axis='x', rotation=45)
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, coverage in enumerate(coverages):
            axes[0, 1].text(i, coverage + 1, f'{coverage:.1f}%', ha='center', va='bottom')
        
        # 3. æ¯”ç‡åˆ†å¸ƒï¼ˆçªå‡ºæ˜¾ç¤ºå™ªå£°èŒƒå›´ï¼‰
        axes[1, 0].hist(df['OpenCloseRatio'], bins=100, alpha=0.7, color='lightcoral', edgecolor='black')
        
        # æ ‡è®°ä¸åŒçš„å™ªå£°èŒƒå›´
        axes[1, 0].axvspan(0.999, 1.001, alpha=0.3, color='green', label='Â±0.1%å™ªå£°èŒƒå›´')
        axes[1, 0].axvspan(0.988, 1.012, alpha=0.2, color='yellow', label='Â±1.2%è¯¯å·®èŒƒå›´')
        axes[1, 0].axvline(df['OpenCloseRatio'].mean(), color='red', linestyle='--', label=f'å‡å€¼: {df["OpenCloseRatio"].mean():.4f}')
        
        axes[1, 0].set_xlabel('å¼€ç›˜ä»·/å‰æ”¶ä»·æ¯”ç‡')
        axes[1, 0].set_ylabel('é¢‘æ¬¡')
        axes[1, 0].set_title('æ¯”ç‡åˆ†å¸ƒï¼ˆå™ªå£°èŒƒå›´æ ‡è®°ï¼‰')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. ç´¯ç§¯åˆ†å¸ƒå‡½æ•°
        sorted_ratios = np.sort(df['OpenCloseRatio'])
        cumulative_prob = np.arange(1, len(sorted_ratios) + 1) / len(sorted_ratios)
        
        axes[1, 1].plot(sorted_ratios, cumulative_prob, linewidth=2, color='blue')
        axes[1, 1].axhline(0.5, color='red', linestyle='--', alpha=0.7, label='50%åˆ†ä½æ•°')
        axes[1, 1].axhline(0.68, color='orange', linestyle='--', alpha=0.7, label='68%åˆ†ä½æ•°')
        axes[1, 1].axhline(0.95, color='green', linestyle='--', alpha=0.7, label='95%åˆ†ä½æ•°')
        
        axes[1, 1].set_xlabel('å¼€ç›˜ä»·/å‰æ”¶ä»·æ¯”ç‡')
        axes[1, 1].set_ylabel('ç´¯ç§¯æ¦‚ç‡')
        axes[1, 1].set_title('æ¯”ç‡ç´¯ç§¯åˆ†å¸ƒå‡½æ•°')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        volatility_chart_file = self.output_dir / 'volatility_analysis.png'
        plt.savefig(volatility_chart_file, dpi=300, bbox_inches='tight')
        logging.info(f"æ³¢åŠ¨ç‡å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {volatility_chart_file}")
        
        plt.show()
    
    def analyze_sampling_statistics(self, df):
        """åˆ†æé‡‡æ ·ç»Ÿè®¡ä¿¡æ¯"""
        logging.info("åˆ†æé‡‡æ ·ç»Ÿè®¡ä¿¡æ¯...")
        
        if 'SampleYear' not in df.columns:
            logging.warning("æ•°æ®ä¸­æ²¡æœ‰é‡‡æ ·ä¿¡æ¯ï¼Œè·³è¿‡é‡‡æ ·ç»Ÿè®¡")
            return
        
        # æŒ‰å¹´æœˆç»Ÿè®¡é‡‡æ ·æ•°æ®
        sampling_stats = df.groupby(['SampleYear', 'SampleMonth']).agg({
            'SecuCode': 'count',
            'OpenCloseRatio': ['mean', 'std', 'min', 'max'],
            'OpenCloseRatioPct': ['mean', 'std', 'min', 'max']
        }).round(6)
        
        # é‡å‘½ååˆ—
        sampling_stats.columns = [
            'æ ·æœ¬æ•°', 'å¹³å‡æ¯”ç‡', 'æ¯”ç‡æ ‡å‡†å·®', 'æœ€å°æ¯”ç‡', 'æœ€å¤§æ¯”ç‡',
            'å¹³å‡æ¶¨è·Œå¹…', 'æ¶¨è·Œå¹…æ ‡å‡†å·®', 'æœ€å°æ¶¨è·Œå¹…', 'æœ€å¤§æ¶¨è·Œå¹…'
        ]
        
        # é‡ç½®ç´¢å¼•
        sampling_stats = sampling_stats.reset_index()
        
        # æ·»åŠ å¹´æœˆæ ‡è¯†
        sampling_stats['å¹´æœˆ'] = sampling_stats['SampleYear'].astype(str) + '-' + sampling_stats['SampleMonth'].astype(str).str.zfill(2)
        
        # ä¿å­˜é‡‡æ ·ç»Ÿè®¡
        sampling_file = self.output_dir / 'sampling_statistics.csv'
        sampling_stats.to_csv(sampling_file, index=False, encoding='utf-8-sig')
        logging.info(f"é‡‡æ ·ç»Ÿè®¡å·²ä¿å­˜åˆ°: {sampling_file}")
        
        # è®¡ç®—æ€»ä½“é‡‡æ ·ç»Ÿè®¡
        total_samples = len(df)
        total_months = len(sampling_stats)
        avg_samples_per_month = total_samples / total_months if total_months > 0 else 0
        
        overall_sampling_stats = {
            'æ€»é‡‡æ ·æ•°': total_samples,
            'é‡‡æ ·æœˆä»½æ•°': total_months,
            'å¹³å‡æ¯æœˆé‡‡æ ·æ•°': avg_samples_per_month,
            'é‡‡æ ·æ—¶é—´èŒƒå›´': f"{df['SampleYear'].min()}-{df['SampleMonth'].min():02d} åˆ° {df['SampleYear'].max()}-{df['SampleMonth'].max():02d}",
            'é‡‡æ ·è‚¡ç¥¨æ•°': df['SecuCode'].nunique(),
            'é‡‡æ ·æ¿å—æ•°': df['ListedSector'].nunique()
        }
        
        # ä¿å­˜æ€»ä½“ç»Ÿè®¡
        overall_file = self.output_dir / 'overall_sampling_stats.csv'
        overall_df = pd.DataFrame(list(overall_sampling_stats.items()), columns=['æŒ‡æ ‡', 'å€¼'])
        overall_df.to_csv(overall_file, index=False, encoding='utf-8-sig')
        logging.info(f"æ€»ä½“é‡‡æ ·ç»Ÿè®¡å·²ä¿å­˜åˆ°: {overall_file}")
        
        return sampling_stats, overall_sampling_stats


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='åˆ†æå¼€ç›˜ä»·ä¸å‰ä¸€æ—¥æ”¶ç›˜ä»·çš„æ¯”ç‡å…³ç³»')
    parser.add_argument('--start', default='2024-01-01', help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end', default='2024-12-31', help='ç»“æŸæ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--sampling', action='store_true', default=True, help='ä½¿ç”¨éšæœºé‡‡æ ·ï¼ˆæ¯æœˆ1000æ¡ï¼‰')
    parser.add_argument('--no-sampling', dest='sampling', action='store_false', help='ä½¿ç”¨å…¨é‡æ•°æ®')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    analyzer = OpenCloseRatioAnalyzer(
        start_date=args.start,
        end_date=args.end
    )
    
    analyzer.run_analysis(use_sampling=args.sampling)


if __name__ == '__main__':
    main() 